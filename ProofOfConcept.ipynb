{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating the Anisotropic Ginzburg-Landau Equation using Physics-Informed Neural Networks\n",
    "\n",
    "Este notebook busca ser más que nada un proof of concept. Para correrlo es recomendable crear un entorno virtual (con python -m venv .venv), activarlo con source .venv/bin/activate y luego instalar las dependencias con pip install -r requirements.txt (asumiendo que lo llama desde el mismo directorio). De lo contrario puede que se instalen un montón de cosas en el ambiente global de python que no es lo ideal y podrían haber choques con las versiones.\n",
    "\n",
    "## La ecuación en sí:\n",
    "\n",
    "Antes de meterme con la ecuación forzada anisotrópica, veamos si es posible integrar esta ecuación:\n",
    "\n",
    "$$\n",
    "\\partial_t A = \\mu A + \\nabla^2 A - A |A|^2\n",
    "$$\n",
    "\n",
    "Esta es la ecuación de Ginzburg-Landau compleja de toda la vida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    }
   ],
   "source": [
    "# Numpy y matplotlib\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librería con la magia pues\n",
    "import deepxde as dde\n",
    "# torch.set_default_device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las condiciones iniciales:\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "UV = sio.loadmat('./uv_2x1602x100x100_Euler_[dt=0.0125,HighOrderLap].mat')['uv']\n",
    "U0 = UV[0:1, 100:101, :, :][0, 0, :, :]\n",
    "V0 = UV[1:2, 100:101, :, :][0, 0, :, :]\n",
    "\n",
    "g0 = np.transpose(UV[0:2, 100:101, :, :][:, 0, :, :], (1, 2, 0))\n",
    "\n",
    "domain = 0.2*np.arange(0, 100)\n",
    "w_0 = scipy.interpolate.RegularGridInterpolator((domain, domain), U0, method=\"cubic\")\n",
    "z_0 = scipy.interpolate.RegularGridInterpolator((domain, domain), V0, method=\"cubic\")\n",
    "f_0 = scipy.interpolate.RegularGridInterpolator((domain, domain), g0, method=\"cubic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo algunos dominios:\n",
    "\n",
    "x_lower = -5\n",
    "x_upper = 5\n",
    "\n",
    "y_lower = -5\n",
    "y_upper = 5\n",
    "\n",
    "t_lower = 0\n",
    "t_upper = 10.0\n",
    "\n",
    "# Space and time domains/geometry (for the deepxde model)\n",
    "space_domain = dde.geometry.Rectangle([x_lower, y_lower], [x_upper, y_upper])\n",
    "time_domain = dde.geometry.TimeDomain(t_lower, t_upper)\n",
    "geomtime = dde.geometry.GeometryXTime(space_domain, time_domain)\n",
    "\n",
    "# IC creation\n",
    "ic_w = dde.icbc.IC(geomtime, lambda xt: w_0(xt[:, :2]), lambda _, on_initial: on_initial, component=0)\n",
    "ic_z = dde.icbc.IC(geomtime, lambda xt: z_0(xt[:, :2]), lambda _, on_initial: on_initial, component=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos nuestra función de pérdida:\n",
    "\n",
    "def lambda_Omega(xy, u):\n",
    "    \"\"\"\n",
    "    Calcula la desviación de la ecuación de Ginzburg-Landau compleja para una función u en un dominio xy.\n",
    "\n",
    "    Parámetros:\n",
    "    - xy: array de tamaño (n, 3) que representa las coordenadas (x, y, t) de los puntos en el dominio.\n",
    "    - u: array de tamaño (n, 2) que representa los valores de la parte real e imaginaria de la función u en el dominio.\n",
    "\n",
    "    Retorna:\n",
    "    - Array de tamaño (n, 1), que da cuenta de la desviación de cumplir la ecuación de Ginzburg-Landau en cada punto de xy.\n",
    "    \"\"\"\n",
    "    \n",
    "    # constantes:\n",
    "    mu = 0.1\n",
    "    beta = 1.0\n",
    "    \n",
    "    w = u[:, 0:1]\n",
    "    z = u[:, 1:2]\n",
    "    \n",
    "    # Derivadas de u\n",
    "    w_t = dde.grad.jacobian(u, xy, i=0, j=2)\n",
    "    z_t = dde.grad.jacobian(u, xy, i=1, j=2) # El índice i para esta fun es el índice del input al que se le calcula el gradiente. El índice j indica la componente del gradiente.\n",
    "    \n",
    "    w_xx = dde.grad.hessian(u, xy, component=0, i=0, j=0)\n",
    "    z_xx = dde.grad.hessian(u, xy, component=1, i=0, j=0)\n",
    "    w_yy = dde.grad.hessian(u, xy, component=0, i=1, j=1)\n",
    "    z_yy = dde.grad.hessian(u, xy, component=1, i=1, j=1)\n",
    "\n",
    "    w_error = mu * (w_xx + w_yy) + (1 - w**2 - z**2) * w + beta * z * (w**2 + z**2) - w_t# fijo mu = 1 porque no sé pasarle parámetros a la función de pérdida todavía y lo otro puede ser computacionalmente costoso.\n",
    "    z_error = mu * (z_xx + z_yy) - beta * (w**2 + z**2) * w + (1 - w**2 - z**2) * z\n",
    "    return [w_error, z_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condiciones Iniciales y de borde mediante transform:\n",
    "\n",
    "def transform(xyt, pretransform_out):\n",
    "    return torch.cos(2*torch.pi*torch.sqrt(xyt[:, 0:1]**2 + xyt[:, 1:2]**2) + 2*torch.arctan2(xyt[:, 1:2], xyt[:, 0:1])) + xyt[:, 2:3] * pretransform_out # esto me asegura que la condición inicial se cumpla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dde.data.TimePDE(\n",
    "    geomtime,\n",
    "    lambda_Omega,\n",
    "    #[ic_w, ic_z],\n",
    "    [],\n",
    "    num_domain=100,\n",
    "    num_boundary=1,\n",
    "    num_initial=1,\n",
    "    train_distribution=\"pseudo\",\n",
    ")\n",
    "\n",
    "\n",
    "# Network architecture\n",
    "net = dde.nn.FNN([3] + [80] * 4 + [2], \"tanh\", \"Glorot normal\")\n",
    "\n",
    "net.apply_output_transform(transform)\n",
    "\n",
    "model = dde.Model(data, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.718319 s\n",
      "\n",
      "Training model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "rocblaslt error: Cannot read /home/miga/Documents/GitHub/Reacto-Difuso/.devenv/profile/lib/hipblaslt/library/TensileLibrary_lazy_gfx1101.dat: No such file or directory\n",
      "\n",
      "rocblaslt error: Could not load /home/miga/Documents/GitHub/Reacto-Difuso/.devenv/profile/lib/hipblaslt/library/TensileLibrary_lazy_gfx1101.dat\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: HIPBLAS_STATUS_INVALID_VALUE when calling `hipblasLtMatmulAlgoGetHeuristic( ltHandle, computeDesc.descriptor(), Adesc.descriptor(), Bdesc.descriptor(), Cdesc.descriptor(), Cdesc.descriptor(), preference.descriptor(), 1, &heuristicResult, &returnedResult)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Es recomendado utilizar aceleración con GPU, es más fácil si es una GPU de NVIDIA lamentablemente.\u001b[39;00m\n\u001b[32m      2\u001b[39m model.compile(\u001b[33m\"\u001b[39m\u001b[33madam\u001b[39m\u001b[33m\"\u001b[39m, lr=\u001b[32m1e-3\u001b[39m, loss=\u001b[33m\"\u001b[39m\u001b[33mMSE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Reacto-Difuso/.devenv/state/venv/lib/python3.12/site-packages/deepxde/utils/internal.py:22\u001b[39m, in \u001b[36mtiming.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     21\u001b[39m     ts = timeit.default_timer()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     te = timeit.default_timer()\n\u001b[32m     24\u001b[39m     verbose = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Reacto-Difuso/.devenv/state/venv/lib/python3.12/site-packages/deepxde/model.py:687\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs, verbose)\u001b[39m\n\u001b[32m    685\u001b[39m \u001b[38;5;28mself\u001b[39m.train_state.set_data_train(*\u001b[38;5;28mself\u001b[39m.data.train_next_batch(\u001b[38;5;28mself\u001b[39m.batch_size))\n\u001b[32m    686\u001b[39m \u001b[38;5;28mself\u001b[39m.train_state.set_data_test(*\u001b[38;5;28mself\u001b[39m.data.test())\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[38;5;28mself\u001b[39m.callbacks.on_train_begin()\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optimizers.is_external_optimizer(\u001b[38;5;28mself\u001b[39m.opt_name):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Reacto-Difuso/.devenv/state/venv/lib/python3.12/site-packages/deepxde/model.py:880\u001b[39m, in \u001b[36mModel._test\u001b[39m\u001b[34m(self, verbose)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_test\u001b[39m(\u001b[38;5;28mself\u001b[39m, verbose=\u001b[32m1\u001b[39m):\n\u001b[32m    876\u001b[39m     \u001b[38;5;66;03m# TODO Now only print the training loss in rank 0. The correct way is to print the average training loss of all ranks.\u001b[39;00m\n\u001b[32m    877\u001b[39m     (\n\u001b[32m    878\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.y_pred_train,\n\u001b[32m    879\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.loss_train,\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_outputs_losses\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_aux_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_state.y_pred_test, \u001b[38;5;28mself\u001b[39m.train_state.loss_test = \u001b[38;5;28mself\u001b[39m._outputs_losses(\n\u001b[32m    887\u001b[39m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    888\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.X_test,\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.y_test,\n\u001b[32m    890\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.test_aux_vars,\n\u001b[32m    891\u001b[39m     )\n\u001b[32m    893\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_state.y_test, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Reacto-Difuso/.devenv/state/venv/lib/python3.12/site-packages/deepxde/model.py:593\u001b[39m, in \u001b[36mModel._outputs_losses\u001b[39m\u001b[34m(self, training, inputs, targets, auxiliary_vars)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m backend_name == \u001b[33m\"\u001b[39m\u001b[33mpytorch\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    592\u001b[39m     \u001b[38;5;28mself\u001b[39m.net.requires_grad_(requires_grad=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m     outs = \u001b[43moutputs_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauxiliary_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.net.requires_grad_()\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m backend_name == \u001b[33m\"\u001b[39m\u001b[33mjax\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    596\u001b[39m     \u001b[38;5;66;03m# TODO: auxiliary_vars\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Reacto-Difuso/.devenv/state/venv/lib/python3.12/site-packages/deepxde/model.py:342\u001b[39m, in \u001b[36mModel._compile_pytorch.<locals>.outputs_losses_train\u001b[39m\u001b[34m(inputs, targets, auxiliary_vars)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moutputs_losses_train\u001b[39m(inputs, targets, auxiliary_vars):\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutputs_losses\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauxiliary_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlosses_train\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Reacto-Difuso/.devenv/state/venv/lib/python3.12/site-packages/deepxde/model.py:319\u001b[39m, in \u001b[36mModel._compile_pytorch.<locals>.outputs_losses\u001b[39m\u001b[34m(training, inputs, targets, auxiliary_vars, losses_fn)\u001b[39m\n\u001b[32m    317\u001b[39m     inputs = torch.as_tensor(inputs)\n\u001b[32m    318\u001b[39m     inputs.requires_grad_()\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m outputs_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m# Data losses\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/bj77ya60z1rhlm2g09sijx1hs5lsc3av-devenv-profile/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/bj77ya60z1rhlm2g09sijx1hs5lsc3av-devenv-profile/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Reacto-Difuso/.devenv/state/venv/lib/python3.12/site-packages/deepxde/nn/pytorch/fnn.py:46\u001b[39m, in \u001b[36mFNN.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m     41\u001b[39m     x = \u001b[38;5;28mself\u001b[39m._input_transform(x)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j, linear \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.linears[:-\u001b[32m1\u001b[39m]):\n\u001b[32m     43\u001b[39m     x = (\n\u001b[32m     44\u001b[39m         \u001b[38;5;28mself\u001b[39m.activation[j](linear(x))\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.activation, \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.activation(\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     47\u001b[39m     )\n\u001b[32m     48\u001b[39m x = \u001b[38;5;28mself\u001b[39m.linears[-\u001b[32m1\u001b[39m](x)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._output_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/bj77ya60z1rhlm2g09sijx1hs5lsc3av-devenv-profile/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/bj77ya60z1rhlm2g09sijx1hs5lsc3av-devenv-profile/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/bj77ya60z1rhlm2g09sijx1hs5lsc3av-devenv-profile/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/bj77ya60z1rhlm2g09sijx1hs5lsc3av-devenv-profile/lib/python3.12/site-packages/torch/utils/_device.py:104\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: HIPBLAS_STATUS_INVALID_VALUE when calling `hipblasLtMatmulAlgoGetHeuristic( ltHandle, computeDesc.descriptor(), Adesc.descriptor(), Bdesc.descriptor(), Cdesc.descriptor(), Cdesc.descriptor(), preference.descriptor(), 1, &heuristicResult, &returnedResult)`"
     ]
    }
   ],
   "source": [
    "# Es recomendado utilizar aceleración con GPU, es más fácil si es una GPU de NVIDIA lamentablemente.\n",
    "model.compile(\"adam\", lr=1e-3, loss=\"MSE\")\n",
    "model.train(iterations=5_000, display_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.000630 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss              Test loss               Test metric\n",
      "10000     [1.89e+01, 3.08e+01]    [1.89e+01, 3.08e+01]    []  \n",
      "\n",
      "Best model at step 10000:\n",
      "  train loss: 4.97e+01\n",
      "  test loss: 4.97e+01\n",
      "  test metric: []\n",
      "\n",
      "'train' took 0.007489 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Further optim with L-BFGS-B\n",
    "model.compile(\"L-BFGS-B\")\n",
    "losshistory, train_state = model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La red ya fue entrenada, ahora veamos si lo que tira tiene sentido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the 2D domain (for plotting and input)\n",
    "# plt.close(\"all\")\n",
    "# time_to_plot = 7.0  # forma burda de seleccionar el tiempo a plotear.\n",
    "\n",
    "# x = np.linspace(x_lower, x_upper, 256)\n",
    "# y = np.linspace(y_lower, y_upper, 256)\n",
    "# t = np.array([time_to_plot])\n",
    "\n",
    "# X, Y, T = np.meshgrid(x, y, t)\n",
    "\n",
    "# X_star = np.hstack((X.flatten()[:, None], Y.flatten()[:, None], T.flatten()[:, None]))\n",
    "# X_doublestar = np.hstack((X.flatten()[:, None], Y.flatten()[:, None]))\n",
    "\n",
    "# # Predecimos:\n",
    "# prediction = model.predict(X_star, operator=None)\n",
    "# print(prediction.shape)\n",
    "\n",
    "# # Reshape the prediction to match the grid shape\n",
    "# U_pred = prediction[:, 0].reshape(X.shape[:2])\n",
    "# V_pred = prediction[:, 1].reshape(X.shape[:2])\n",
    "\n",
    "# # Plotting\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# ax[0].imshow(\n",
    "#     U_pred,\n",
    "#     interpolation=\"nearest\",\n",
    "#     cmap=\"viridis\",\n",
    "#     extent=[x_lower, x_upper, y_lower, y_upper],\n",
    "#     origin=\"lower\",\n",
    "#     aspect=\"auto\",\n",
    "# )\n",
    "# ax[0].set_title(\"u(x, y)\")\n",
    "\n",
    "# ax[1].imshow(\n",
    "#     V_pred,\n",
    "#     interpolation=\"nearest\",\n",
    "#     cmap=\"viridis\",\n",
    "#     extent=[x_lower, x_upper, y_lower, y_upper],\n",
    "#     origin=\"lower\",\n",
    "#     aspect=\"auto\",\n",
    "# )\n",
    "# ax[1].set_title(\"v(x, y)\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6095b223453f44d1b17deb48d140d310",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=1500.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lo mismo pero con animación:\n",
    "plt.close()\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "x = np.linspace(x_lower, x_upper, 256)\n",
    "y = np.linspace(y_lower, y_upper, 256)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "def animate(t):\n",
    "    t = np.array([t])\n",
    "    X, Y, T = np.meshgrid(x, y, t)\n",
    "\n",
    "    X_star = np.hstack((X.flatten()[:, None], Y.flatten()[:, None], T.flatten()[:, None]))\n",
    "    prediction = model.predict(X_star, operator=None)\n",
    "    U_pred = prediction[:, 0].reshape(X.shape[:2])\n",
    "    V_pred = prediction[:, 1].reshape(X.shape[:2])\n",
    "    ax[0].clear()\n",
    "    ax[1].clear()\n",
    "    ax[0].imshow(\n",
    "        U_pred,\n",
    "        interpolation=\"nearest\",\n",
    "        cmap=\"viridis\",\n",
    "        extent=[x_lower, x_upper, y_lower, y_upper],\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    ax[0].set_title(\"u(x, y) at t={:.2f}\".format(t[0]))\n",
    "    ax[1].imshow(\n",
    "        V_pred,\n",
    "        interpolation=\"nearest\",\n",
    "        cmap=\"viridis\",\n",
    "        extent=[x_lower, x_upper, y_lower, y_upper],\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "    ax[1].set_title(\"v(x, y) at t={:.2f}\".format(t[0]))\n",
    "    return ax,\n",
    "\n",
    "ani = FuncAnimation(fig, animate, frames=np.linspace(0, 10, 101), blit=False, repeat=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
